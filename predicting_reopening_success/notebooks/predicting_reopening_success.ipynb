{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Re-Opening Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from matplotlib.pylab import plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import pyplot, lines\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import researchpy as rpy\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime \n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = 'eu_us'  #Â Will be used to tag the saved files\n",
    "\n",
    "lockdown_dataset = '../data/processed/expanded_lockdowns.pkl'\n",
    "\n",
    "from_rebound_days, to_rebound_days = 28, 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs_dataset = '../data/processed/efs_{}.pkl'.format(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Lockdown Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 13:46:42.166 | INFO     | __main__:<module>:1 - Loading lockdown data @ ../data/expanded_lockdowns.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15533, 68)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info('Loading lockdown data @ %s' % lockdown_dataset)\n",
    "\n",
    "expanded_lockdowns = pd.read_pickle(lockdown_dataset)\n",
    "expanded_lockdowns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13849, 67)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Focus on individual countries rather than regional aggregations.\n",
    "ignore_regional_aggregations = expanded_lockdowns['aggregation']!=expanded_lockdowns['region']\n",
    "expanded_lockdowns = expanded_lockdowns[ignore_regional_aggregations].set_index('aggregation')\n",
    "expanded_lockdowns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the Lockdowns to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6404, 67)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dataset == 'eu_us':\n",
    "    use_expanded_lockdowns = expanded_lockdowns[(expanded_lockdowns['region'].isin(['eu', 'us']))]\n",
    "    \n",
    "else:\n",
    "    use_expanded_lockdowns = expanded_lockdowns\n",
    "    \n",
    "    \n",
    "use_expanded_lockdowns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6398, 67), 0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: The last two lockdowns for each country are duplicates. Drop one. Need to check why this is the case.\n",
    "use_expanded_lockdowns = use_expanded_lockdowns.drop_duplicates()\n",
    "use_expanded_lockdowns.shape, use_expanded_lockdowns.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Re-Opening Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_features = [\n",
    "    'lockdown_min_mobility_level', 'lockdown_mean_mobility_level', \n",
    "\n",
    "    'lockdown_duration_days', \n",
    "    \n",
    "    'lockdown_days_to_peak_cases', 'lockdown_days_from_peak_cases', \n",
    "    'lockdown_entry_level_cases', 'lockdown_exit_level_cases', \n",
    "    'lockdown_peak_value_cases_per_million', 'lockdown_mean_value_cases_per_million',   \n",
    "    \n",
    "    'lockdown_days_to_peak_deaths', 'lockdown_days_from_peak_deaths', \n",
    "    'lockdown_entry_level_deaths', 'lockdown_exit_level_deaths', \n",
    "    'lockdown_peak_value_deaths_per_100k', 'lockdown_mean_value_deaths_per_100k', \n",
    "    \n",
    "]\n",
    "\n",
    "len(use_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test EU/US Lockdowns\n",
    "We need to pick a fixed number of days after reopening and then we will evaluate classifcation operformance wrt this number of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7696428571428571"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebound_days = 42\n",
    "use_lockdowns_for_days = use_expanded_lockdowns[use_expanded_lockdowns['rebound_duration_days']==rebound_days]\n",
    "\n",
    "X = use_lockdowns_for_days[use_features]\n",
    "\n",
    "y = use_lockdowns_for_days['is_increasing_rebound']\n",
    "\n",
    "scaled_X = pd.DataFrame(preprocessing.scale(X), columns=X.columns, index=X.index)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "scores = cross_validate(clf, scaled_X, y, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute-Force Feature Selection Analysis\n",
    "We using the `mlxtend` library to do an exhaustive feature selection alaysis. This takes the form of a simple wrapper that can be used to wrap a CV evaluation for a given classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Exhaustive Feature Search\n",
    "We use the EFS wrapper to perform a 10-fold CV for all possible combinations of features in `use_features` and we perform this for a range of different rebound days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 13:23:43.539 | INFO     | __main__:<module>:1 - Running exhaustive feature search (28 - 85 days. This will take a while ... (~12 hours)\n"
     ]
    }
   ],
   "source": [
    "logger.info('Running exhaustive feature search (%s - %s days. This will take a while ... (~12 hours)' % (from_rebound_days, to_rebound_days))\n",
    "\n",
    "efs_results = []\n",
    "\n",
    "check_rebound_days = range(from_rebound_days, to_rebound_days, 1)\n",
    "\n",
    "for rebound_days in check_rebound_days:\n",
    "    \n",
    "    if rebound_days//10==0:\n",
    "        logger.info('EFS for %s rebound days for %s lockdowns' % (rebound_days, len(use_lockdowns_for_days)))\n",
    "\n",
    "\n",
    "    \n",
    "    # The lockdowns for the number of rebound days.\n",
    "    use_lockdowns_for_days = use_expanded_lockdowns[use_expanded_lockdowns['rebound_duration_days']==rebound_days]\n",
    "\n",
    "    # The feature and target class data\n",
    "    X = use_lockdowns_for_days[use_features]\n",
    "    y = use_lockdowns_for_days['is_increasing_rebound']\n",
    "\n",
    "    scaled_X = pd.DataFrame(preprocessing.scale(X), columns=X.columns, index=X.index)\n",
    "\n",
    "    clf = GradientBoostingClassifier()\n",
    "\n",
    "    efs = EFS(clf, \n",
    "               min_features=1,\n",
    "               max_features=len(use_features),\n",
    "               scoring='accuracy',\n",
    "               print_progress=False,\n",
    "               cv=10, \n",
    "               n_jobs=-1)\n",
    "    \n",
    "    efs = efs.fit(scaled_X, y)\n",
    "    \n",
    "    max_class_prob = max(use_lockdowns_for_days['is_successful_rebound'].mean(), 1-use_lockdowns_for_days['is_successful_rebound'].mean())\n",
    "    \n",
    "    efs_results.append((rebound_days, len(use_lockdowns_for_days), max_class_prob, efs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The EFS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 13:49:34.810 | INFO     | __main__:<module>:30 - Finished with 65534 results\n"
     ]
    }
   ],
   "source": [
    "def get_efs_results(efs_results):\n",
    "    \n",
    "    # Collect the DFs from the EFS results, adding the rebound days.\n",
    "    efs_dfs = []\n",
    "    for (rebound_days, size, max_class_prob, efs_result) in efs_results:\n",
    "        efs_result_df = pd.DataFrame.from_dict(efs_result.get_metric_dict()).T\n",
    "        efs_result_df['rebound_days'] = rebound_days\n",
    "        efs_result_df['dataset_size'] = size\n",
    "        efs_result_df['max_class_prob'] = max_class_prob\n",
    "        efs_dfs.append(efs_result_df)\n",
    "\n",
    "    # Combine into a single df\n",
    "    efs_df = pd.concat(efs_dfs, ignore_index=True)\n",
    "    \n",
    "    # Add/fix various features\n",
    "    efs_df['n'] = efs_df['feature_names'].map(len)\n",
    "    \n",
    "    efs_df['rank'] = efs_df['avg_score'].rank(ascending=False, pct=True)\n",
    "\n",
    "    # For some reason these cols are of type object which messes with aggregation so change them to floats\n",
    "    # as they should have been in the fitsy place.\n",
    "\n",
    "    efs_df ['avg_score'] = efs_df ['avg_score'].astype(float)\n",
    "    efs_df ['ci_bound'] = efs_df ['ci_bound'].astype(float)\n",
    "    efs_df ['std_dev'] = efs_df ['std_dev'].astype(float)\n",
    "    efs_df ['std_err'] = efs_df ['std_err'].astype(float)\n",
    "\n",
    "    return efs_df.sort_values(by=['rebound_days', 'avg_score'], ascending=False).reset_index().drop('index', axis='columns')\n",
    "\n",
    "logger.info('Finished with %s results' % len(efs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "      <th>rebound_days</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>max_class_prob</th>\n",
       "      <th>n</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(6, 7)</td>\n",
       "      <td>[1.0, 0.875, 0.875, 0.75, 0.75, 1.0, 0.875, 1....</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>(lockdown_exit_level_cases, lockdown_peak_valu...</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>0.094170</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 5, 6, 14)</td>\n",
       "      <td>[1.0, 1.0, 0.875, 0.75, 0.75, 0.875, 0.875, 1....</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>(lockdown_mean_mobility_level, lockdown_entry_...</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>0.094170</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5, 6, 8, 9)</td>\n",
       "      <td>[1.0, 1.0, 0.875, 0.75, 0.75, 1.0, 0.75, 1.0, ...</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>(lockdown_entry_level_cases, lockdown_exit_lev...</td>\n",
       "      <td>0.081336</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.036504</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3, 4, 5, 6, 9, 12, 14)</td>\n",
       "      <td>[1.0, 1.0, 0.875, 0.75, 0.75, 0.875, 0.875, 1....</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>(lockdown_days_to_peak_cases, lockdown_days_fr...</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>0.094170</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(6,)</td>\n",
       "      <td>[1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.875, 1.0,...</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>(lockdown_exit_level_cases,)</td>\n",
       "      <td>0.087584</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature_idx                                          cv_scores  \\\n",
       "0                   (6, 7)  [1.0, 0.875, 0.875, 0.75, 0.75, 1.0, 0.875, 1....   \n",
       "1            (1, 5, 6, 14)  [1.0, 1.0, 0.875, 0.75, 0.75, 0.875, 0.875, 1....   \n",
       "2             (5, 6, 8, 9)  [1.0, 1.0, 0.875, 0.75, 0.75, 1.0, 0.75, 1.0, ...   \n",
       "3  (3, 4, 5, 6, 9, 12, 14)  [1.0, 1.0, 0.875, 0.75, 0.75, 0.875, 0.875, 1....   \n",
       "4                     (6,)  [1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.875, 1.0,...   \n",
       "\n",
       "   avg_score                                      feature_names  ci_bound  \\\n",
       "0   0.898214  (lockdown_exit_level_cases, lockdown_peak_valu...  0.069941   \n",
       "1   0.898214  (lockdown_mean_mobility_level, lockdown_entry_...  0.069941   \n",
       "2   0.898214  (lockdown_entry_level_cases, lockdown_exit_lev...  0.081336   \n",
       "3   0.898214  (lockdown_days_to_peak_cases, lockdown_days_fr...  0.069941   \n",
       "4   0.887500                       (lockdown_exit_level_cases,)  0.087584   \n",
       "\n",
       "    std_dev   std_err  rebound_days  dataset_size  max_class_prob  n      rank  \n",
       "0  0.094170  0.031390            29            77        0.545455  2  0.000076  \n",
       "1  0.094170  0.031390            29            77        0.545455  4  0.000076  \n",
       "2  0.109512  0.036504            29            77        0.545455  4  0.000076  \n",
       "3  0.094170  0.031390            29            77        0.545455  7  0.000076  \n",
       "4  0.117925  0.039308            29            77        0.545455  1  0.000252  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs_df = get_efs_results(efs_results)\n",
    "efs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save EFS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 13:49:49.274 | INFO     | __main__:<module>:1 - Saving EFS dataset -> ../data/efs_eu_us.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(65534, 12)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info('Saving EFS dataset -> %s' % efs_dataset)\n",
    "\n",
    "efs_df.to_pickle(efs_dataset)\n",
    "efs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COVID-19",
   "language": "python",
   "name": "covid-19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
